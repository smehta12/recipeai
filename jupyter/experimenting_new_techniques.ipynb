{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f7209-7720-42c3-a4f7-7ac077c9721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_community.vectorstores.docarray.in_memory import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd4a89-a1c0-4add-ac89-c24e3df6c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40d545f-ddf5-4e42-b8ca-e8464246d7ef",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07b3fe-d485-4e7a-a581-419745bec1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_df = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 39):\n",
    "    file = f\"../data/recipe_page_{i}.csv\"\n",
    "    recipe_df = pd.read_csv(file, usecols=[\"recipe_name\", \"ingredients\", \"recipe\", \"tags\"])\n",
    "    csv_df=pd.concat([csv_df, recipe_df], ignore_index=True)\n",
    "print(csv_df.shape)\n",
    "\n",
    "# Shuffle rows\n",
    "csv_df = csv_df.sample(frac=1).reset_index(drop=True)\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235a700-506e-4cbf-bc52-2b81666fe8e2",
   "metadata": {},
   "source": [
    "### Make Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006b7f8-b634-47b4-a0bd-e2cb10d55c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/langchain-ai/langchain/issues/12601\n",
    "# Modified to create dictionary with column name and value\n",
    "from typing import Any, Iterator, List, Union\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "\n",
    "\n",
    "class BaseDataFrameLoader(BaseLoader):\n",
    "    def __init__(self, data_frame: Any, *, page_content_column: Union[str, List[str]] = \"text\"):\n",
    "        \"\"\"Initialize with dataframe object.\n",
    "\n",
    "        Args:\n",
    "            data_frame: DataFrame object.\n",
    "            page_content_column: Name of the column or list of column names containing the page content.\n",
    "              Defaults to \"text\".\n",
    "        \"\"\"\n",
    "        self.data_frame = data_frame\n",
    "        self.page_content_column = page_content_column\n",
    "\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        \"\"\"Lazy load records from dataframe.\"\"\"\n",
    "\n",
    "        for idx, row in self.data_frame.iterrows():\n",
    "            if isinstance(self.page_content_column, list):\n",
    "                text = ' '.join(f'{col}:{row[col]}' for col in self.page_content_column)\n",
    "            else:\n",
    "                text = f'{col}:{row[self.page_content_column]}'\n",
    "            metadata = row.to_dict()\n",
    "            if isinstance(self.page_content_column, list):\n",
    "                for col in self.page_content_column:\n",
    "                    metadata.pop(col, None)\n",
    "            else:\n",
    "                metadata.pop(self.page_content_column, None)\n",
    "            yield Document(page_content=text, metadata=metadata)\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load full dataframe.\"\"\"\n",
    "        return list(self.lazy_load())\n",
    "\n",
    "\n",
    "class DataFrameLoader(BaseDataFrameLoader):\n",
    "    \"\"\"Load `Pandas` DataFrame.\"\"\"\n",
    "\n",
    "    def __init__(self, data_frame: Any, page_content_column: Union[str, List[str]] = \"text\"):\n",
    "        \"\"\"Initialize with dataframe object.\n",
    "\n",
    "        Args:\n",
    "            data_frame: Pandas DataFrame object.\n",
    "            page_content_column: Name of the column or list of column names containing the page content.\n",
    "              Defaults to \"text\".\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import pandas as pd\n",
    "        except ImportError as e:\n",
    "            raise ImportError(\n",
    "                \"Unable to import pandas, please install with `pip install pandas`.\"\n",
    "            ) from e\n",
    "\n",
    "        if not isinstance(data_frame, pd.DataFrame):\n",
    "            raise ValueError(\n",
    "                f\"Expected data_frame to be a pd.DataFrame, got {type(data_frame)}\"\n",
    "            )\n",
    "        super().__init__(data_frame, page_content_column=page_content_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e06d4a-3d8c-49b3-b508-9eff4784fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataFrameLoader(csv_df, page_content_column=[\"recipe_name\", \"ingredients\", \"recipe\", \"tags\"])\n",
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20133fd6-bbcb-48d2-adf6-e3bae7d498a1",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff8d8c-990a-4b00-8b90-e054b744a65e",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f904d-0819-4787-9bae-31d5409496f3",
   "metadata": {},
   "source": [
    "- `Alibaba-NLP/gte-large-en-v1.5`, open AI `text-embedding-3-large` emebdding model worked better so far.\n",
    "-  `Alibaba-NLP/gte-large-en-v1.5` is very slow due to large size.\n",
    "-  open AI `text-embedding-3-large` Can be expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d7801-00e9-46c2-9b2b-488c2442f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name='Alibaba-NLP/gte-large-en-v1.5', model_kwargs=dict(trust_remote_code=True))\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name='Snowflake/snowflake-arctic-embed-m-long', model_kwargs=dict(trust_remote_code=True))\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c73d730-492d-4c6c-b4ff-37209334c5a7",
   "metadata": {},
   "source": [
    "### Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad5904-ba47-4d6d-bdf0-3d2b044781b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = DocArrayInMemorySearch.from_documents(\n",
    "#     docs, \n",
    "#     embedding_model\n",
    "# )\n",
    "# db = Chroma.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1144138-83e0-4819-89db-4870630e4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca90ae-b4eb-4b53-bed4-a397d41f97e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exmaple\n",
    "# query = \"Show me all recipes which uses Yellow moong\" #\"Show me all shaak recipe\" # \"Show me all dhokla recipe\" #\"Recipes which has besan as ingredients\"\n",
    "# # query = \"Show me all shaak recipes dish. Must avoid to look at word which are not shaak or shak\"\n",
    "query = f\"Can you share recipe for onion, potato and peas. Don't include shaak or sabji?\"\n",
    "searched_docs = db.similarity_search_with_relevance_scores(query, k=4)\n",
    "for d in searched_docs:\n",
    "    print(d)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f5091-8e05-4d2a-a3d8-0b0a317d2df3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "queries = [\"Show me all recipes which uses Yellow moong\", \n",
    "           \"Show me all shaak recipe\", \n",
    "           \"Show me all shaak recipes dish. Must avoid to look at word which are not shaak or shak\",\n",
    "           \"Show me all dhokla recipe\",\n",
    "           \"Recipes which has besan as ingredients\",\n",
    "           \"I have dudhi/doodhi at home. Can you find me a recipe?\",\n",
    "           \"I am craving for dosa. Can you show me recipes?\",\n",
    "           \"Can you share recipe for onion, potato and peas. Don't include shaak or sabji?\"\n",
    "          ]\n",
    "for q in queries:\n",
    "    print(f\"Query: {q}\")\n",
    "    searched_docs = db.similarity_search_with_relevance_scores(q, k=4)\n",
    "    for d in searched_docs:\n",
    "        print(d)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928aa4f2-88f9-4819-bd0e-b20ea564b984",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f8e7c-af0e-4e2a-8c48-a0f0b7e20fcf",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee0e8e-11f0-44b0-9402-72df6247e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"stabilityai/stablelm-3b-4e1t\", #\"meta-llama/Meta-Llama-3-8B\",\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "#     timeout=600\n",
    "# )\n",
    "\n",
    "# q = \"Provide all the recipe names, its recipe and all the ingrediants that uses besan. Do not provide or generate anything else.\"\n",
    "# response = index.query(q, llm=llm)\n",
    "# display(Markdown(response))\n",
    "\n",
    "# from langchain_openai import OpenAI\n",
    "# llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "llm = Ollama(model=\"llama3\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304d42b-37c0-42d0-b89d-bad28c08cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "qdocs = \"\".join([searched_docs[i][0].page_content for i in range(len(searched_docs))])\n",
    "final_query = f\"{qdocs} Question: {query} in a table in markdown and summarize each one\"\n",
    "response = llm.invoke(final_query)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f750a-fde5-4d3d-bc35-bb777bba9df5",
   "metadata": {},
   "source": [
    "### Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd92a38-bf8d-434a-bc06-745191707970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "import langchain\n",
    "\n",
    "langchain.debug = False\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold': 0.2})\n",
    "# For above steps, create LangChain chain\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\",\n",
    "    verbose=True,\n",
    "    retriever=retriever, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42b89d-b540-4013-b165-dfab9ae7295a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hellucinating with similar looking shak recipe. Like Shakarpara. But this is very wide query.\n",
    "# prompt = f\"Show me all shaak recipes dish. Must avoid to look at word which are not shaak or shak. Do not include Shakarpara\" \n",
    "\n",
    "# prompt = f\"Show me all recipes which uses Yellow moong\"\n",
    "\n",
    "# prompt = f\"I have dudhi/doodhi at home. Can you find me a recipe?\" # Hellucinating big time!\n",
    "# prompt = f\"I am craving for dosa. Can you show me recipes?\" # which are not farali or for upvas?\"\n",
    "# prompt = f\"Can you share recipe for onion, potato and peas. Exclude shaak or sabji?\"\n",
    "prompt = f\"Show me one dhokla recipe\"\n",
    "response = qa_stuff.run(prompt + \" List all of the ingredients and the whole recipe to make from the document. Present in good format\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f04d8-f17e-4baa-a9ca-7987018d59df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p in queries:\n",
    "    print(f\"***Prompt: {p}\")\n",
    "    response = qa_stuff.run(p + \" List all of the ingredients and the whole recipe to make from the document. Present in good format\")\n",
    "    print(display(Markdown(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6398999-9865-4ef0-844a-ac7816985c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5347e02-e964-4d1c-88e0-93bad2751d48",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e32ba9d-0fdb-4de1-b9ed-b31f2091bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072de86-4c02-43fd-a250-d650545b4a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = Client()\n",
    "\n",
    "# Define dataset: these are your test cases\n",
    "dataset_name = \"QA Example Dataset\"\n",
    "dataset = client.create_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0f8f9-2d8d-444d-82bd-300719861164",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_examples(\n",
    "    inputs=[\n",
    "        # {\"question\": \"Show me all recipes which uses Yellow moong\"},\n",
    "        # {\"question\": \"Show me all shaak recipe\"},\n",
    "        {\"question\": \"Show me one dhokla recipe\"},\n",
    "        # {\"question\": \"Recipes which has besan as ingredients\"},\n",
    "        {\"question\": \"I have dudhi/doodhi at home. Can you find me a recipe?\"}\n",
    "        # {\"question\": \"I am craving for dosa. Can you show me recipes?\"},\n",
    "    ],\n",
    "    outputs=[\n",
    "         {\"answer\": \"**Soft and Tasty Khaman Dhokla**\\n\\n**Ingredients:**\\n\\n* 2 cups besan (bengal gram flour)\\n* 2 green chillies, chopped\\n* 2 tbsp sugar\\n* Salt to taste\\n* 5 to 6 curry leaves (kadi patta)\\n* 1 tsp citric acid (nimbu ka phool)\\n* 1 tsp baking soda\\n* 1/4 cup freshly grated coconut\\n* 1/4 cup chopped coriander (dhania)\\n\\n**Recipe:**\\n\\n1. Combine the besan, salt and sugar in a bowl, add little water and mix well using hands.\\n2. Add the citric acid and mix well.\\n3. Add the baking soda, while stirring continuously for 1 minute.\\n4. Pour this solution in a greased plate and steam for 8-10 mins or till the dokla is cooked.\\n5. Heat the oil in a small pan and add the mustard seeds, curry leaves and green chillies.\\n6. Pour this tempering to the dhoklas and keep aside.\\n7. Heat 1/2 cup water and 1 tbsp sugar in a pan and pour the solution on it.\\n8. Garnish with coriander and grated coconut.\"},\n",
    "         {\"answer\": \"Mixed Vegetable Handvo, Instant Gujarati Handvo recipe - How to make Mixed Vegetable Handvo, Instant Gujarati Handvo\tFor The Handvo Batter:  2 cups readymade idli batter  1/4 cup grated bottle gourd (doodhi / lauki)  1/4 cup finely chopped spinach (palak)  2 tbsp grated onions  2 tbsp grated carrot  2 tbsp finely chopped coriander (dhania)  1 tsp sugar  1 tsp green chilli paste  1/2 tsp garlic (lehsun) paste  1/4 tsp turmeric powder (haldi)  1/2 tsp chilli powder  salt to taste  Other Ingredients For Mixed Vegetable Handvo:  6 tsp oil  1 1/2 tsp mustard seeds ( rai / sarson)  1 1/2 tsp sesame seeds (til)  3 pinches of asafoetida (hing)  For Serving With Mixed Vegetable Handvo:  green chutney\tFor the handvo batter Combine all the ingredients along with approx. 2 tbsp of water in a deep bowl and mix well. Keep aside. How to proceed To make  mixed vegetable handvo  , divide the handvo batter into 3 equal portions and keep aside. Heat 2 tsp of oil in a small non-stick pan, add ½ tsp of mustard seeds, ½ tsp of sesame seeds and a pinch of asafoetida and sauté on a medium flame for 30 seconds. Pour a portion of the prepared handvo batter and spread it evenly, cover with a lid and cook on a medium flame for 3 to 4 minutes or till it turns golden brown in colour. Turnover and again cover with a lid and cook on a medium flame for 3 to 4 minutes or till it turns golden brown in colour from the other side as well. Remove on a chopping board, cut the   into 4 equal pieces. Repast steps 2 to 5 to make 2 more  mixed vegetable handvos . Serve the handvo  immediately with green chutney.\"}\n",
    "    ],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e03c01-a342-4eda-890c-5270a0c7f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langsmith.evaluation import LangChainStringEvaluator\n",
    "\n",
    "_PROMPT_TEMPLATE = \"\"\"You are an expert gujarati chef to find out whether the recipies are correct or not.\n",
    "You are checking the following recipe requests:\n",
    "{query}\n",
    "Here is the real answer:\n",
    "{answer}\n",
    "You are grading the following predicted answer:\n",
    "{result}\n",
    "Respond with GOOD or BAD:\n",
    "Grade:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\", \"result\"], template=_PROMPT_TEMPLATE)\n",
    "\n",
    "eval_llm = ChatOpenAI(temperature=0.0)\n",
    "\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\": eval_llm, \"prompt\": PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e70ce-1758-47c4-b16d-e5a7e78854ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "\n",
    "def evaluate_length(run: Run, example: Example) -> dict:\n",
    "    prediction = run.outputs.get(\"output\") or \"\"\n",
    "    required = example.outputs.get(\"answer\") or \"\"\n",
    "    score = int(len(prediction) < 2 * len(required))\n",
    "    return {\"key\":\"length\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda9160-7809-48a7-9716-ac0978159b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_app(prompt):\n",
    "    return qa_stuff.run(prompt + \" List all of the ingredients and the whole recipe to make from the document. Present in good format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e61d9b9-b400-450c-a1b9-f570a3e5d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langsmith_app(inputs):\n",
    "    output = recipe_app(inputs[\"question\"])\n",
    "    return {\"output\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407a85f-6320-4714-8e47-34e743c61902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    langsmith_app, # Your AI system\n",
    "    data=dataset_name, # The data to predict and grade over\n",
    "    evaluators=[evaluate_length, qa_evaluator], # The evaluators to score the results\n",
    "    experiment_prefix=\"ollama3\", # A prefix for your experiment names to easily identify them\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
