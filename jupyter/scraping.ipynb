{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db258438-2e8f-4476-8a65-0cdfa1df1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup, SoupStrainer, Tag\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff84631-538d-4db7-be8e-e4bb87b061b2",
   "metadata": {},
   "source": [
    "## Per Page Recipe Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9a629-af9a-43cf-bce0-a808a467fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =  \\\n",
    "\"https://www.tarladalal.com/sabudana-pakoras-14757r\"\n",
    "# \"https://www.tarladalal.com/chakli-instant-chakli-40487r\"\n",
    "# \"https://www.tarladalal.com/pressure-cooker-oondhiya-4337r\"\n",
    "# \"https://www.tarladalal.com/bajra-dhebra-recipe-gujarati-tea-time-snack-42272r\"\n",
    "# \"https://www.tarladalal.com/sabudana-khichdi-in-microwave-2749r\"\n",
    "# \"https://www.tarladalal.com/sweet-shakarpara-baked-sweet-shakar-para-41973r\"\n",
    "# \"https://www.tarladalal.com/vegetable-stuffed-upma-cutlet-36118r\"\n",
    "# \"https://www.tarladalal.com/surti-undhiyu-40596r\"\n",
    "# \"https://www.tarladalal.com/cauliflower-nu-bhanolu--gujarati-recipe-560r\"\n",
    "# \"https://www.tarladalal.com/instant-lemon-pickle--zero-oil-22184r\"\n",
    "# \"https://www.tarladalal.com/sprouts-spring-onion-and-tomato-salad-2957r\" \n",
    "# \"https://www.tarladalal.com/khandvi-gujarati-snack-recipe-557r\" \n",
    "# \"https://www.tarladalal.com/sabudana-khichdi-in-microwave-2749r\"\n",
    "hdr = {'User-Agent':'Mozilla/5.0'}\n",
    "header= {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \n",
    "      'AppleWebKit/537.11 (KHTML, like Gecko) '\n",
    "      'Chrome/23.0.1271.64 Safari/537.11',\n",
    "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "      'Accept-Encoding': 'none',\n",
    "      'Accept-Language': 'en-US,en;q=0.8',\n",
    "      'Connection': 'keep-alive'}\n",
    "req = urllib.request.Request(url=url, headers=header) \n",
    "page = urllib.request.urlopen(req).read()\n",
    "soup = BeautifulSoup(page.decode(\"utf-8\", \"html.parser\"))\n",
    "\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage.decode(\"utf-8\", \"html.parser\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef6c46-c604-4929-ac39-1d36192b0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/shalin/t.html\", 'w') as f:\n",
    "    f.write(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba16f5-1457-4e00-9dce-470055fbdc42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ing_sections = soup.find_all('span', id=lambda x: x and x.startswith('ingsection'))\n",
    "\n",
    "recipes_ingredients = \"\"\n",
    "# Iterate over each 'ingsection' and print its content\n",
    "for section in ing_sections:\n",
    "    if not recipes_ingredients:\n",
    "        recipes_ingredients += section.text.strip() + \":\"\n",
    "    else:\n",
    "        recipes_ingredients += \";\" + section.text.strip() + \":\"\n",
    "    next_sibling = section.find_next_sibling()  # Get the next sibling\n",
    "    siblings = []\n",
    "    while next_sibling:\n",
    "        if next_sibling.name == 'span' and next_sibling.has_attr('class') and 'recipe_subheader' in next_sibling['class']:\n",
    "            break  # Break if next sibling is another 'ingsection'\n",
    "        if next_sibling.text.strip():\n",
    "            siblings.append(next_sibling.text.strip())\n",
    "        next_sibling = next_sibling.find_next_sibling()  # Move to the next sibling\n",
    "    recipes_ingredients += \", \".join(siblings)\n",
    "recipes_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe404e-5375-4b66-a116-8cfe738695c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', id='ctl00_cntrightpanel_lblrecipeNameH2').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ecd54-f810-4887-81f3-0d8aae525df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For https://www.tarladalal.com/vegetable-stuffed-upma-cutlet-36118r, there's section in the recipe steps. Needs sections in the recipes too\n",
    "recipe_small_steps_div = soup.find('div', id='recipe_small_steps')\n",
    "# recipe_small_steps_div.find_all('span')\n",
    "for span in recipe_small_steps_div.find_all('li'):\n",
    "    print(span.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34ed58-37f4-49be-aa34-0baf58003694",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_small_steps_subheaders = soup.find_all(class_='recipe_subheader')\n",
    "recipe_small_steps_subheaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c151e4-1d26-45ef-8cc3-b71a5df8be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_ingrediants(soup, url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b7732-2a80-48b7-83d2-b1e298fc0254",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdiv = soup.find('div', id=\"rcpinglist\")\n",
    "for sp in rdiv.select('span'):\n",
    "    if sp.has_attr('itemprop'):\n",
    "        print(sp.text.strip())\n",
    "    elif sp.has_attr('class') and 'recipe_subheader' in sp['class']:\n",
    "        print(sp.text.strip() + \":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24443dad-3e85-4bcc-99d2-3c42137e6c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = soup.find('div', id=\"recipe_small_steps\").get_text(\"\\n\").strip()\n",
    "print(rec)\n",
    "print()\n",
    "print(\"\\n\".join(list(dict.fromkeys(rec.split(\"\\n\")))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec7fc5-e7f8-4079-8b2d-6ee468572298",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_small_steps_subheaders = soup.find_all(class_='recipe_subheader')\n",
    "steps = []\n",
    "for subheader in recipe_small_steps_subheaders:\n",
    "    if subheader.has_attr('id') and subheader['id'].startswith('procsection'):\n",
    "        # print(subheader)\n",
    "        print(subheader.text.strip())  # Print subheader text\n",
    "        # Find the parent ol element\n",
    "        parent_ol = subheader.find_next('ol')\n",
    "        # Find all li elements under the parent ol\n",
    "        recipe_steps = parent_ol.find_all('li')\n",
    "        # Extract and print the text for each step\n",
    "        for step in recipe_steps:\n",
    "            print(step.span.text.strip())\n",
    "            steps.append(step.span.text.strip())\n",
    "if not steps:\n",
    "    recipe_small_steps_div = soup.find('div', id='recipe_small_steps')\n",
    "    # recipe_small_steps_div.find_all('span')\n",
    "    for span in recipe_small_steps_div.find_all('li'):\n",
    "        print(span.get_text())\n",
    "        steps.append(span.get_text())\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f3609-98c3-4a1e-a0b8-c265b8f7f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_span = soup.find('span', id='ctl00_cntrightpanel_lblServes')\n",
    "# text_in_parent_span = ''.join([str(x) for x in parent_span.contents if isinstance(x, str)])\n",
    "print(text_in_parent_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1ccca-4038-4587-add0-7ffccaeb0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_tag = soup.find('time', itemprop='totalTime')\n",
    "print(time_tag)\n",
    "span_tag = time_tag.find('span')\n",
    "if span_tag:\n",
    "    span_tag.decompose()\n",
    "print(time_tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f247ac-538c-47cb-bf4d-881b6a7d5707",
   "metadata": {},
   "outputs": [],
   "source": [
    "soaking_time_element = soup.find(text=lambda text: 'Soaking time' in text)\n",
    "print(soaking_time_element.split(':')[1].split('\\xa0')[1])\n",
    "# Extract the soaking time value\n",
    "if soaking_time_element:\n",
    "    soaking_time = soaking_time_element.split(':')[1].split('\\xa0')[1].strip()\n",
    "    print(\"Soaking time:\", soaking_time)\n",
    "else:\n",
    "    print(\"Soaking time not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6aa4f-4451-4932-b4cf-3a7f70dbf809",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', id='ctl00_cntrightpanel_lblrecipeNameH2').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242324e-075e-4ba0-91b3-7b9007a3318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find('div', id='recipe_tags').get_text(\"\\n\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a7265-ca41-4059-9070-d3998261cdb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_time_and_serving(soup, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5282704-21ed-454e-be40-addf6a82ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_div = soup.find('div', id='recipe_tags')\n",
    "p_tag = tags_div.find_next('p')\n",
    "for t in p_tag.find_all('time'):\n",
    "    t.decompose()\n",
    "for serv_time in p_tag.find_all('span', attrs=dict(id=\"ctl00_cntrightpanel_lblServes\")):\n",
    "    serv_time.decompose()\n",
    "print(p_tag.get_text().\n",
    "      replace(\"Preparation Time:\", \"\").\n",
    "      replace(\"Cooking Time:\", \"\").\n",
    "      replace(\"Total Time:\", \"\").\n",
    "      replace(\"&nbsp\", \"\").\n",
    "      split(\"Show me for\")[0].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd1e6e-7205-4a41-a6eb-416a4544f6f6",
   "metadata": {},
   "source": [
    "## Page Links Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69977561-aae2-4e12-97b2-194a4743d349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "links_url = \"https://www.tarladalal.com/recipes-for-veg-recipes-gujarati-24?pageindex=1\" #\"https://www.tarladalal.com/sprouts-spring-onion-and-tomato-salad-2957r\" # \"https://www.tarladalal.com/sabudana-khichdi-in-microwave-2749r\" #\n",
    "links_header= {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \n",
    "      'AppleWebKit/537.11 (KHTML, like Gecko) '\n",
    "      'Chrome/23.0.1271.64 Safari/537.11',\n",
    "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "      'Accept-Encoding': 'none',\n",
    "      'Accept-Language': 'en-US,en;q=0.8',\n",
    "      'Connection': 'keep-alive'}\n",
    "links_req = urllib.request.Request(url=links_url, headers=links_header) \n",
    "links_page = urllib.request.urlopen(links_req).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0d945-a524-4093-bab5-34f9e461aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_soup = BeautifulSoup(links_page.decode(\"utf-8\", \"html.parser\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27324f-26aa-4ece-9387-ac670d348222",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca102c-fb63-4547-9c9a-9b653e544c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in links_soup.findAll('div', class_=\"rcc_rcpcore\"):\n",
    "    print(div)\n",
    "    print(\"**********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e315a6-d330-47da-918a-5e05fe3cf66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sp in links_soup.find_all('span', attrs={\"class\":\"rcc_recipename\"}):\n",
    "    print(sp.text)\n",
    "    print(sp.find('a', href=True)['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f48b5-886d-409f-bd25-fe17fd183ef1",
   "metadata": {},
   "source": [
    "# Final Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389888c8-221e-4f55-830a-b6ce3b8d40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage(links_url):\n",
    "    try:\n",
    "        links_header= {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \n",
    "          'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "          'Chrome/123.0.0.0 Safari/537.36',\n",
    "          'Accept': '*/*', #'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "          'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "          'Accept-Encoding': 'none',\n",
    "          'Accept-Language': 'en-US,en;q=0.9',\n",
    "          'Connection': 'keep-alive',\n",
    "        }\n",
    "        links_req = urllib.request.Request(url=links_url, headers=links_header) \n",
    "        try:\n",
    "            links_page = urllib.request.urlopen(links_req, timeout=90).read()\n",
    "            # print(links_page)\n",
    "        except urllib.error.HTTPError:\n",
    "            logging.exception(f\"Error when getting webpage from {links_url}\")\n",
    "            time.sleep(120)\n",
    "            logging.info(\"Retrying......\")\n",
    "            try:\n",
    "                links_page = urllib.request.urlopen(links_req, timeout=90).read()\n",
    "            except:\n",
    "                logging.warning(\"Retry Failed!!!\")\n",
    "                return \n",
    "        links_soup = BeautifulSoup(links_page.decode(\"utf-8\", \"html.parser\"))\n",
    "        return links_soup\n",
    "    except:\n",
    "        logging.exception(f\"Error when getting webpage code for {links_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a82117-a94a-49f2-adb1-b9c4392f2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingrediants(soup, page_link):\n",
    "    recipes_ingredients = \"\"\n",
    "    try:\n",
    "        ing_list = []\n",
    "        rdiv = soup.find('div', id=\"rcpinglist\")\n",
    "        for sp in rdiv.select('span'):\n",
    "            if sp.has_attr('itemprop'):\n",
    "                ing_list.append(sp.text.strip())\n",
    "            elif sp.has_attr('class') and 'recipe_subheader' in sp['class']:\n",
    "                ing_list.append(sp.text.strip() + \":\")\n",
    "        recipes_ingredients = \"\\n \".join(ing_list)\n",
    "    except:\n",
    "        logging.exception(f\"Exception when finding ingrediants of {page_link}\")\n",
    "    \n",
    "    if not recipes_ingredients:\n",
    "        logging.warning(f\"Cannot find recipe ingredients for {page_link}\")\n",
    "    return recipes_ingredients        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31efe23f-3103-4c05-94bc-bc7e51f223b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe(soup, page_link):\n",
    "    recipe = \"\"\n",
    "    try:\n",
    "        rec = soup.find('div', id=\"recipe_small_steps\").get_text(\"\\n\").strip()\n",
    "        recipe = \"\\n\".join(list(dict.fromkeys(rec.split(\"\\n\"))))\n",
    "    except:\n",
    "        logging.exception(f\"Exception when finding recipe for {page_link}\")\n",
    "\n",
    "    if not recipe:\n",
    "        logging.warning(f\"Cannot find recipe method for {page_link}\")\n",
    "    return recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e392c8-ec63-4fcb-9765-1b5ff9f69fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_and_serving(soup, page_link):\n",
    "    times = \"\"\n",
    "    servings = \"\"\n",
    "    other_info = \"\"\n",
    "    try:\n",
    "        prep_time = \"\"\n",
    "        cook_time = \"\"\n",
    "        total_tie = \"\"\n",
    "        \n",
    "        servings_tag = soup.find('span', attrs=dict(itemprop=\"recipeYield\"))\n",
    "        if servings_tag:\n",
    "            servings = str(servings_tag.text)\n",
    "        \n",
    "        prep_tag = soup.find('time', attrs=dict(itemprop=\"prepTime\"))\n",
    "        if prep_tag:\n",
    "            prep_time = prep_tag.text\n",
    "            times += \"Preparation Time: \" + prep_time+ \", \"\n",
    "\n",
    "        cook_tag = soup.find('time', attrs=dict(itemprop=\"cookTime\"))\n",
    "        if cook_tag:\n",
    "            cook_time = cook_tag.text\n",
    "            times += \"Cooking Time: \" + cook_time + \", \"\n",
    "        \n",
    "        total_time_tag = soup.find('time', itemprop='totalTime')\n",
    "        if total_time_tag:\n",
    "            span_tag = total_time_tag.find('span')\n",
    "            if span_tag:\n",
    "                span_tag.decompose()\n",
    "            total_time = total_time_tag.text\n",
    "            times += \"Total Time: \" + total_time + \", \"\n",
    "  \n",
    "        # Other time or coocking related info\n",
    "        tags_div = soup.find('div', id='recipe_tags')\n",
    "        if not tags_div:\n",
    "            tags_div = soup.find('div', id='ctl00_cntrightpanel_lblrecipeNameH2')\n",
    "            \n",
    "        p_tag = tags_div.find_next('p')\n",
    "        for t in p_tag.find_all('time'):\n",
    "            t.decompose()\n",
    "        if servings:\n",
    "            for serv_time in p_tag.find_all('span', attrs=dict(id=\"ctl00_cntrightpanel_lblServes\")):\n",
    "                serv_time.decompose()\n",
    "        \n",
    "        other_info = p_tag.get_text().replace(\"&nbsp\", \" \").split(\"Show me for\")[0].strip()        \n",
    "        if prep_time:\n",
    "              other_info = other_info.replace(\"Preparation Time:\", \"\")\n",
    "        if cook_time:\n",
    "              other_info = other_info.replace(\"Cooking Time:\", \"\")\n",
    "        if total_time:\n",
    "              other_info = other_info.replace(\"Total Time:\", \"\")\n",
    "        \n",
    "        times += other_info\n",
    "    \n",
    "    except:\n",
    "        logging.exception(f\"Error while finding time and serving for {page_link}\") \n",
    "\n",
    "    if not times or not servings:\n",
    "        logging.warning(f\"Cannot find times, or servings for {page_link}\")\n",
    "    return times, servings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818fee2c-b35c-4cb3-97e9-11cd88d03fc0",
   "metadata": {},
   "source": [
    "#### Get the pages and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a72278f-67f7-43f3-b75f-5a017bfd3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine = \"mh\"\n",
    "base_data_dir = f\"../data/{cuisine}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d1724d0-44b5-499a-b2c2-e4438076c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_pages_info = {\n",
    "    \"gj\": {\"list_page_url\": \"https://www.tarladalal.com/recipes-for-veg-recipes-gujarati-24?pageindex={0}\",\n",
    "          \"last_list_page_num\": 38\n",
    "          },\n",
    "    \"mh\": {\"list_page_url\": \"https://www.tarladalal.com/recipes-for-veg-recipes-maharashtrian-52?pageindex={0}\",\n",
    "           \"last_list_page_num\": 21\n",
    "          }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae0f599e-ef99-42f7-8b7d-2a20e883ab12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2852753426.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[23], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    if not recipdef e_page:\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# recipe_list_page_url = \"https://www.tarladalal.com/recipes-for-veg-recipes-maharashtrian-52?pageindex={0}\" #\"https://www.tarladalal.com/recipes-for-veg-recipes-gujarati-24?pageindex={0}\"\n",
    "recipe_url_prefix = \"https://www.tarladalal.com/\"\n",
    "for recipe_list_page_idx in range(1, recipe_pages_info[cuisine][\"last_list_page_num\"]+1):\n",
    "    recipe_list = []\n",
    "    print(f\"Getting recipies from page {recipe_list_page_idx}\")\n",
    "    list_url = recipe_pages_info[cuisine][\"list_page_url\"].format(recipe_list_page_idx)\n",
    "    recipe_list_page = get_webpage(list_url)\n",
    "    if not recipe_list_page:\n",
    "        continue\n",
    "    for recipe_span in recipe_list_page.find_all('span', attrs={\"class\":\"rcc_recipename\"}):\n",
    "        df_row = {}\n",
    "        df_row[\"recipe_list_url\"] = list_url\n",
    "        df_row[\"recipe_name\"] = recipe_span.text\n",
    "        recipe_url = recipe_url_prefix + recipe_span.find('a', href=True)['href']\n",
    "        df_row[\"recipe_url\"] = recipe_url    \n",
    "        # print(recipe_url)\n",
    "        recipe_page = get_webpage(recipe_url)\n",
    "        if not recipdef e_page:\n",
    "            logging.warn(f\"Couldn't find recipe page for {recipe_url}\")\n",
    "            continue\n",
    "        df_row[\"recipe_long_name\"] = recipe_page.find('span', id='ctl00_cntrightpanel_lblrecipeNameH2').text\n",
    "        df_row[\"ingredients\"] = get_ingrediants(recipe_page, recipe_url)\n",
    "        df_row[\"recipe\"] = get_recipe(recipe_page, recipe_url)\n",
    "        df_row[\"tags\"] = recipe_page.find('div', id='recipe_tags').get_text(\"\\n\").strip()\n",
    "        if not df_row[\"tags\"]:\n",
    "            logging.warn(f\"Couldn't find tags for {recipe_url}\")\n",
    "        times, servings = get_time_and_serving(recipe_page, recipe_url)\n",
    "        df_row[\"times\"] = times\n",
    "        df_row[\"servings\"] = servings\n",
    "        recipe_list.append(df_row)\n",
    "    recipe_df = pd.DataFrame(recipe_list)\n",
    "    recipe_df.to_csv(f\"{base_data_dir}/recipe_page_{recipe_list_page_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb791b6f-d929-4eec-a4f0-f5afb9a1419c",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "Page 1: Need other times in addition of cooking etc time.\n",
    "\n",
    "All Pages, \n",
    "- In recipe, if there's only . then remove it and remove line.\n",
    "If starts with \"To make\" then merge next line with it\n",
    "If starts with , then merge with previous line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa77b440-0d78-4e89-9a06-da6c19a79b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipes_df(page_id):\n",
    "    pg_location = f\"{base_data_dir}/recipe_page_{page_id}.csv\"\n",
    "    if not os.path.exists(pg_location):\n",
    "        print(f\"Page Id Missing: {page_id}\")\n",
    "        return pd.DataFrame()\n",
    "    return pd.read_csv(pg_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5565852-07d7-4029-bb5c-ce8ad3d08e41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Idx: 1\n",
      "Less ing for https://www.tarladalal.com/how-to-make-rajgira-flour-amaranth-flour-at-home-42738r\n",
      "Page Idx: 2\n",
      "Page Idx: 3\n",
      "Less ing for https://www.tarladalal.com/how-to-make-hung-curd-42765r\n",
      "Less ing for https://www.tarladalal.com/phulka-recipe-indian-chapati-recipe-4392r\n",
      "Less ing for https://www.tarladalal.com/jowar-roti-41569r\n",
      "Page Idx: 4\n",
      "Page Idx: 5\n",
      "Page Idx: 6\n",
      "Less recipe for https://www.tarladalal.com/green-chutney--mumbai-roadside-recipes-33414r\n",
      "Less recipe for https://www.tarladalal.com/sukhi-lehsun-chutney--mumbai-roadside-recipes--33381r\n",
      "Page Idx: 7\n",
      "Less ing for https://www.tarladalal.com/sunny-side-up-eggs-breakfast-recipe-42311r\n",
      "Page Idx: 8\n",
      "Less ing for https://www.tarladalal.com/pomegranate-tea-turkish-tea-41740r\n",
      "Page Idx: 9\n",
      "Page Idx: 10\n",
      "Page Idx: 11\n",
      "Less recipe for https://www.tarladalal.com/geela-lehsun-chutney-33382r\n",
      "Page Idx: 12\n",
      "Less ing for https://www.tarladalal.com/how-to-roast-onion-roasted-onions-22531r\n",
      "Page Idx: 13\n",
      "Less ing for https://www.tarladalal.com/tamarind-water-imli-ka-pani-225r\n",
      "Less recipe for https://www.tarladalal.com/teekha-chutney--mumbai-roadside-recipes--33380r\n",
      "Less recipe for https://www.tarladalal.com/fruit-punch--party-drinks--33218r\n",
      "Page Idx: 14\n",
      "Page Idx: 15\n",
      "Less recipe for https://www.tarladalal.com/flax-seeds-chutney-37339r\n",
      "Page Idx: 16\n",
      "Page Idx: 17\n",
      "Less ing for https://www.tarladalal.com/mango-wadi-38363r\n",
      "Page Idx: 18\n",
      "Less recipe for https://www.tarladalal.com/coriander-chutney-37715r\n",
      "Less recipe for https://www.tarladalal.com/sweet-poha-36270r\n",
      "Less recipe for https://www.tarladalal.com/sabudana-shira-9513r\n",
      "Page Idx: 19\n",
      "Less ing for https://www.tarladalal.com/jowar-bhakri-34113r\n",
      "Less ing for https://www.tarladalal.com/cucumber-poha-32163r\n",
      "Less recipe for https://www.tarladalal.com/thalipeeth-15145r\n",
      "Less recipe for https://www.tarladalal.com/rava-bhakri-15380r\n",
      "Less recipe for https://www.tarladalal.com/cucumber-poha-32163r\n",
      "Page Idx: 20\n",
      "Less ing for https://www.tarladalal.com/raw-mango-murabba-38366r\n",
      "Less recipe for https://www.tarladalal.com/sabo-dana-khichdi-9123r\n",
      "Page Idx: 21\n"
     ]
    }
   ],
   "source": [
    "for page_id in range(1, recipe_pages_info[cuisine][\"last_list_page_num\"]+1):\n",
    "    df = get_recipes_df(page_id)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    print(f\"Page Idx: {page_id}\")\n",
    "    for idx, row in df.iterrows():\n",
    "        if len(df.loc[idx, \"recipe_ing\"].split(\"\\n\")) <= 3:\n",
    "            print(f'Less ing for {row[\"recipe_url\"]}')\n",
    "    for idx, row in df.iterrows():\n",
    "        if len(df.loc[idx, \"recipe\"].split(\"\\n\")) <= 3:\n",
    "            print(f'Less recipe for {row[\"recipe_url\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7fc8bba-e0e6-4151-8463-54b37af7af76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Idx: 1\n",
      "Page Idx: 2\n",
      "Page Idx: 3\n",
      "Page Idx: 4\n",
      "Page Idx: 5\n",
      "Page Idx: 6\n",
      "Page Idx: 7\n",
      "Page Idx: 8\n",
      "Page Idx: 9\n",
      "Page Idx: 10\n",
      "Page Idx: 11\n",
      "Page Idx: 12\n",
      "Page Idx: 13\n",
      "Page Idx: 14\n",
      "Page Idx: 15\n",
      "Page Idx: 16\n",
      "Page Idx: 17\n",
      "Page Idx: 18\n",
      "Page Idx: 19\n",
      "Page Idx: 20\n",
      "Page Idx: 21\n"
     ]
    }
   ],
   "source": [
    "# Remove tags from tags column\n",
    "for page_id in range(1, recipe_pages_info[cuisine][\"last_list_page_num\"]+1):\n",
    "    df = get_recipes_df(page_id)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    print(f\"Page Idx: {page_id}\")\n",
    "    # for idx, row in df.iterrows():\n",
    "    df['tags'] = df['tags'].str.replace(\"Tags\", \"\").str.strip()\n",
    "    df.to_csv(f\"{base_data_dir}/recipe_page_{page_id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58d2bafe-10ee-4ca8-97b8-2a99a543f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Id Missing: 1\n",
      "Page Idx: 2\n",
      "Page Id Missing: 3\n",
      "Page Id Missing: 4\n",
      "Page Id Missing: 5\n",
      "Page Id Missing: 6\n",
      "Page Id Missing: 7\n",
      "Page Id Missing: 8\n",
      "Page Id Missing: 9\n",
      "Page Id Missing: 10\n",
      "Page Id Missing: 11\n",
      "Page Id Missing: 12\n",
      "Page Id Missing: 13\n",
      "Page Id Missing: 14\n",
      "Page Id Missing: 15\n",
      "Page Id Missing: 16\n",
      "Page Id Missing: 17\n",
      "Page Id Missing: 18\n",
      "Page Id Missing: 19\n",
      "Page Id Missing: 20\n",
      "Page Id Missing: 21\n"
     ]
    }
   ],
   "source": [
    "# Add missing item name in the last line\n",
    "# Do with \n",
    "# Cool the\n",
    "# Divide the\n",
    "# Use the\n",
    "# Store the\n",
    "# Drain the\n",
    "# Refrigerate the\n",
    "# Garnish the\n",
    "# Break the\n",
    "# Allow the\n",
    "# Serve the anywhere then add recipi and merge next line\n",
    "# If second last word is \"Serve\" then insert the recipi name and merge last line\n",
    "half_sent_samples = [\"Do with\", \"Cool the\", \"Divide the\", \"Use the\", \"Store the\", \"Drain the\", \"Refrigerate the\", \n",
    "             \"Garnish the\", \"Break the\", \"Allow the\", \"Serve the\", \"Cut the\", \"Brush each\",\n",
    "             \"Cool and store the\", \"Serve\", \"Serve or store the\"]\n",
    "half_sent = half_sent_samples.copy()\n",
    "\n",
    "for hs in half_sent_samples:\n",
    "    half_sent.append(hs + \" \")\n",
    "\n",
    "for page_id in range(1, recipe_pages_info[cuisine][\"last_list_page_num\"]+1):\n",
    "    df = get_recipes_df(page_id)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    print(f\"Page Idx: {page_id}\")\n",
    "    df = df.drop([x for x in  ['Unnamed: 0.1','Unnamed: 0'] if x in df.columns], axis=1)\n",
    "    for idx, row in df.iterrows():\n",
    "        recipe = df.loc[idx, \"recipe\"]\n",
    "        lines = recipe.split(\"\\n\")\n",
    "        for sentence in half_sent:\n",
    "            if sentence in lines:\n",
    "                rn = row[\"recipe_name\"]\n",
    "                if '(' in rn:\n",
    "                    rn = rn.split('(')[0].strip()\n",
    "                elif '|' in rn:\n",
    "                    rn = rn.split('|')[0].strip()\n",
    "                elif ',' in rn:\n",
    "                    rn = rn.split(',')[0].strip()\n",
    "    \n",
    "                rn = rn.lower()\n",
    "                for word in [\"raw\", \"how\", \"recipe\", cuisine, \"to\", \"make\"]:\n",
    "                    if word in rn:\n",
    "                        rn = rn.replace(word, \"\")\n",
    "                ln_idx = lines.index(sentence)\n",
    "                lines[ln_idx] = f\"{lines[ln_idx].strip()} {rn.lower().strip()} {lines[ln_idx+1].strip()}\"\n",
    "                del lines[ln_idx+1]\n",
    "                new_recipe = \"\\n\".join(lines)\n",
    "                df.loc[idx, \"recipe\"] = new_recipe\n",
    "    df.to_csv(f\"{base_data_dir}/recipe_page_{page_id}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83572a48-778f-4282-a9ec-3134aa108738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Idx: 1\n",
      "Page Idx: 2\n",
      "Page Idx: 3\n",
      "Page Idx: 4\n",
      "Page Idx: 5\n",
      "Page Idx: 6\n",
      "Page Idx: 7\n",
      "Page Idx: 8\n",
      "Page Idx: 9\n",
      "Page Idx: 10\n",
      "Page Idx: 11\n",
      "Page Idx: 12\n",
      "Page Idx: 13\n",
      "Page Idx: 14\n",
      "Page Idx: 15\n",
      "Page Idx: 16\n",
      "Page Idx: 17\n",
      "Page Idx: 18\n",
      "Page Idx: 19\n",
      "Page Idx: 20\n",
      "Page Idx: 21\n"
     ]
    }
   ],
   "source": [
    "for page_id in range(1, recipe_pages_info[cuisine][\"last_list_page_num\"]+1):\n",
    "    df = get_recipes_df(page_id)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    print(f\"Page Idx: {page_id}\")\n",
    "    df.rename(columns={\"recipe_ing\":\"ingredients\"}, inplace=True)\n",
    "    df.to_csv(f\"{base_data_dir}/recipe_page_{page_id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805189b1-81ba-42ff-b927-cce7e0cb1719",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_id in range(1, recipe_pages_info[cuisine][\"last_list_page_num\"]+1):\n",
    "    df = get_recipes_df(page_id)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    print(f\"Page Idx: {page_id}\")\n",
    "    df = df.drop([x for x in  ['Unnamed: 0.1','Unnamed: 0'] if x in df.columns], axis=1)\n",
    "    # for idx, row in df.iterrows():\n",
    "    # df.rename({\"recipe_ing\":\"ingredients\"}, axis=1, inplace=True)\n",
    "    df.to_csv(f\"{base_data_dir}/recipe_page_{page_id}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
