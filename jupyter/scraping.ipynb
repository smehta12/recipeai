{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db258438-2e8f-4476-8a65-0cdfa1df1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from bs4 import BeautifulSoup, SoupStrainer, Tag\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff84631-538d-4db7-be8e-e4bb87b061b2",
   "metadata": {},
   "source": [
    "## Per Page Recipe Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9a629-af9a-43cf-bce0-a808a467fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =  \\\n",
    "\"https://www.tarladalal.com/sabudana-pakoras-14757r\"\n",
    "# \"https://www.tarladalal.com/chakli-instant-chakli-40487r\"\n",
    "# \"https://www.tarladalal.com/pressure-cooker-oondhiya-4337r\"\n",
    "# \"https://www.tarladalal.com/bajra-dhebra-recipe-gujarati-tea-time-snack-42272r\"\n",
    "# \"https://www.tarladalal.com/sabudana-khichdi-in-microwave-2749r\"\n",
    "# \"https://www.tarladalal.com/sweet-shakarpara-baked-sweet-shakar-para-41973r\"\n",
    "# \"https://www.tarladalal.com/vegetable-stuffed-upma-cutlet-36118r\"\n",
    "# \"https://www.tarladalal.com/surti-undhiyu-40596r\"\n",
    "# \"https://www.tarladalal.com/cauliflower-nu-bhanolu--gujarati-recipe-560r\"\n",
    "# \"https://www.tarladalal.com/instant-lemon-pickle--zero-oil-22184r\"\n",
    "# \"https://www.tarladalal.com/sprouts-spring-onion-and-tomato-salad-2957r\" \n",
    "# \"https://www.tarladalal.com/khandvi-gujarati-snack-recipe-557r\" \n",
    "# \"https://www.tarladalal.com/sabudana-khichdi-in-microwave-2749r\"\n",
    "hdr = {'User-Agent':'Mozilla/5.0'}\n",
    "header= {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \n",
    "      'AppleWebKit/537.11 (KHTML, like Gecko) '\n",
    "      'Chrome/23.0.1271.64 Safari/537.11',\n",
    "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "      'Accept-Encoding': 'none',\n",
    "      'Accept-Language': 'en-US,en;q=0.8',\n",
    "      'Connection': 'keep-alive'}\n",
    "req = urllib.request.Request(url=url, headers=header) \n",
    "page = urllib.request.urlopen(req).read()\n",
    "soup = BeautifulSoup(page.decode(\"utf-8\", \"html.parser\"))\n",
    "\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage.decode(\"utf-8\", \"html.parser\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef6c46-c604-4929-ac39-1d36192b0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/shalin/t.html\", 'w') as f:\n",
    "    f.write(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba16f5-1457-4e00-9dce-470055fbdc42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ing_sections = soup.find_all('span', class_='recipe_subheader', id=)\n",
    "# for i in ing_sections:\n",
    "#     print(i)\n",
    "#     print(\"------------\")\n",
    "ing_sections = soup.find_all('span', id=lambda x: x and x.startswith('ingsection'))\n",
    "\n",
    "recipes_ingredients = \"\"\n",
    "# Iterate over each 'ingsection' and print its content\n",
    "for section in ing_sections:\n",
    "    if not recipes_ingredients:\n",
    "        recipes_ingredients += section.text.strip() + \":\"\n",
    "    else:\n",
    "        recipes_ingredients += \";\" + section.text.strip() + \":\"\n",
    "    next_sibling = section.find_next_sibling()  # Get the next sibling\n",
    "    siblings = []\n",
    "    while next_sibling:\n",
    "        if next_sibling.name == 'span' and next_sibling.has_attr('class') and 'recipe_subheader' in next_sibling['class']:\n",
    "            break  # Break if next sibling is another 'ingsection'\n",
    "        if next_sibling.text.strip():\n",
    "            # print(next_sibling.text.strip())  # Print the content\n",
    "            siblings.append(next_sibling.text.strip())\n",
    "        next_sibling = next_sibling.find_next_sibling()  # Move to the next sibling\n",
    "    recipes_ingredients += \", \".join(siblings)\n",
    "recipes_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe404e-5375-4b66-a116-8cfe738695c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', id='ctl00_cntrightpanel_lblrecipeNameH2').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ecd54-f810-4887-81f3-0d8aae525df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For https://www.tarladalal.com/vegetable-stuffed-upma-cutlet-36118r, there's section in the recipe steps. Needs sections in the recipes too\n",
    "recipe_small_steps_div = soup.find('div', id='recipe_small_steps')\n",
    "# recipe_small_steps_div.find_all('span')\n",
    "for span in recipe_small_steps_div.find_all('li'):\n",
    "    print(span.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34ed58-37f4-49be-aa34-0baf58003694",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_small_steps_subheaders = soup.find_all(class_='recipe_subheader')\n",
    "recipe_small_steps_subheaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c151e4-1d26-45ef-8cc3-b71a5df8be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_ingrediants(soup, url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b7732-2a80-48b7-83d2-b1e298fc0254",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdiv = soup.find('div', id=\"rcpinglist\")\n",
    "for sp in rdiv.select('span'):\n",
    "    if sp.has_attr('itemprop'):\n",
    "        print(sp.text.strip())\n",
    "    elif sp.has_attr('class') and 'recipe_subheader' in sp['class']:\n",
    "        print(sp.text.strip() + \":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24443dad-3e85-4bcc-99d2-3c42137e6c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = soup.find('div', id=\"recipe_small_steps\").get_text(\"\\n\").strip()\n",
    "print(rec)\n",
    "print()\n",
    "print(\"\\n\".join(list(dict.fromkeys(rec.split(\"\\n\")))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec7fc5-e7f8-4079-8b2d-6ee468572298",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_small_steps_subheaders = soup.find_all(class_='recipe_subheader')\n",
    "steps = []\n",
    "for subheader in recipe_small_steps_subheaders:\n",
    "    if subheader.has_attr('id') and subheader['id'].startswith('procsection'):\n",
    "        # print(subheader)\n",
    "        print(subheader.text.strip())  # Print subheader text\n",
    "        # Find the parent ol element\n",
    "        parent_ol = subheader.find_next('ol')\n",
    "        # Find all li elements under the parent ol\n",
    "        recipe_steps = parent_ol.find_all('li')\n",
    "        # Extract and print the text for each step\n",
    "        for step in recipe_steps:\n",
    "            print(step.span.text.strip())\n",
    "            steps.append(step.span.text.strip())\n",
    "if not steps:\n",
    "    recipe_small_steps_div = soup.find('div', id='recipe_small_steps')\n",
    "    # recipe_small_steps_div.find_all('span')\n",
    "    for span in recipe_small_steps_div.find_all('li'):\n",
    "        print(span.get_text())\n",
    "        steps.append(span.get_text())\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f3609-98c3-4a1e-a0b8-c265b8f7f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_span = soup.find('span', id='ctl00_cntrightpanel_lblServes')\n",
    "# text_in_parent_span = ''.join([str(x) for x in parent_span.contents if isinstance(x, str)])\n",
    "print(text_in_parent_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1ccca-4038-4587-add0-7ffccaeb0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_tag = soup.find('time', itemprop='totalTime')\n",
    "print(time_tag)\n",
    "span_tag = time_tag.find('span')\n",
    "if span_tag:\n",
    "    span_tag.decompose()\n",
    "print(time_tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f247ac-538c-47cb-bf4d-881b6a7d5707",
   "metadata": {},
   "outputs": [],
   "source": [
    "soaking_time_element = soup.find(text=lambda text: 'Soaking time' in text)\n",
    "print(soaking_time_element.split(':')[1].split('\\xa0')[1])\n",
    "# Extract the soaking time value\n",
    "if soaking_time_element:\n",
    "    soaking_time = soaking_time_element.split(':')[1].split('\\xa0')[1].strip()\n",
    "    print(\"Soaking time:\", soaking_time)\n",
    "else:\n",
    "    print(\"Soaking time not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6aa4f-4451-4932-b4cf-3a7f70dbf809",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', id='ctl00_cntrightpanel_lblrecipeNameH2').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242324e-075e-4ba0-91b3-7b9007a3318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find('div', id='recipe_tags').get_text(\"\\n\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a7265-ca41-4059-9070-d3998261cdb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_time_and_serving(soup, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5282704-21ed-454e-be40-addf6a82ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_div = soup.find('div', id='recipe_tags')\n",
    "p_tag = tags_div.find_next('p')\n",
    "for t in p_tag.find_all('time'):\n",
    "    t.decompose()\n",
    "for serv_time in p_tag.find_all('span', attrs=dict(id=\"ctl00_cntrightpanel_lblServes\")):\n",
    "    serv_time.decompose()\n",
    "print(p_tag.get_text().\n",
    "      replace(\"Preparation Time:\", \"\").\n",
    "      replace(\"Cooking Time:\", \"\").\n",
    "      replace(\"Total Time:\", \"\").\n",
    "      replace(\"&nbsp\", \"\").\n",
    "      split(\"Show me for\")[0].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd1e6e-7205-4a41-a6eb-416a4544f6f6",
   "metadata": {},
   "source": [
    "## Page Links Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69977561-aae2-4e12-97b2-194a4743d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_url = \"https://www.tarladalal.com/recipes-for-veg-recipes-gujarati-24?pageindex=1\" #\"https://www.tarladalal.com/sprouts-spring-onion-and-tomato-salad-2957r\" # \"https://www.tarladalal.com/sabudana-khichdi-in-microwave-2749r\" #\n",
    "links_header= {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \n",
    "      'AppleWebKit/537.11 (KHTML, like Gecko) '\n",
    "      'Chrome/23.0.1271.64 Safari/537.11',\n",
    "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "      'Accept-Encoding': 'none',\n",
    "      'Accept-Language': 'en-US,en;q=0.8',\n",
    "      'Connection': 'keep-alive'}\n",
    "links_req = urllib.request.Request(url=links_url, headers=links_header) \n",
    "links_page = urllib.request.urlopen(links_req).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0d945-a524-4093-bab5-34f9e461aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_soup = BeautifulSoup(links_page.decode(\"utf-8\", \"html.parser\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27324f-26aa-4ece-9387-ac670d348222",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca102c-fb63-4547-9c9a-9b653e544c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in links_soup.findAll('div', class_=\"rcc_rcpcore\"):\n",
    "    print(div)\n",
    "    print(\"**********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e315a6-d330-47da-918a-5e05fe3cf66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sp in links_soup.find_all('span', attrs={\"class\":\"rcc_recipename\"}):\n",
    "    print(sp.text)\n",
    "    print(sp.find('a', href=True)['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f48b5-886d-409f-bd25-fe17fd183ef1",
   "metadata": {},
   "source": [
    "### Final Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389888c8-221e-4f55-830a-b6ce3b8d40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage(links_url):\n",
    "    try:\n",
    "        links_header= {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \n",
    "          'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "          'Chrome/123.0.0.0 Safari/537.36',\n",
    "          'Accept': '*/*', #'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "          'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "          'Accept-Encoding': 'none',\n",
    "          'Accept-Language': 'en-US,en;q=0.9',\n",
    "          'Connection': 'keep-alive',\n",
    "        }\n",
    "        links_req = urllib.request.Request(url=links_url, headers=links_header) \n",
    "        try:\n",
    "            links_page = urllib.request.urlopen(links_req, timeout=90).read()\n",
    "            # print(links_page)\n",
    "        except urllib.error.HTTPError:\n",
    "            logging.exception(f\"Error when getting webpage from {links_url}\")\n",
    "            time.sleep(120)\n",
    "            logging.info(\"Retrying......\")\n",
    "            try:\n",
    "                links_page = urllib.request.urlopen(links_req, timeout=90).read()\n",
    "            except:\n",
    "                logging.warning(\"Retry Failed!!!\")\n",
    "                return \n",
    "        links_soup = BeautifulSoup(links_page.decode(\"utf-8\", \"html.parser\"))\n",
    "        return links_soup\n",
    "        \n",
    "        # req = Request(\n",
    "        #     url=url, \n",
    "        #     headers={'User-Agent': 'Mozilla/5.0'}\n",
    "        # )\n",
    "        # webpage = urlopen(req).read()\n",
    "        # links_soup = BeautifulSoup(webpage.decode(\"utf-8\", \"html.parser\"))\n",
    "        # return links_soup\n",
    "    except:\n",
    "        logging.exception(f\"Error when getting webpage code for {links_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a82117-a94a-49f2-adb1-b9c4392f2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingrediants(soup, page_link):\n",
    "    recipes_ingredients = \"\"\n",
    "    try:\n",
    "        ing_list = []\n",
    "        rdiv = soup.find('div', id=\"rcpinglist\")\n",
    "        for sp in rdiv.select('span'):\n",
    "            if sp.has_attr('itemprop'):\n",
    "                ing_list.append(sp.text.strip())\n",
    "            elif sp.has_attr('class') and 'recipe_subheader' in sp['class']:\n",
    "                ing_list.append(sp.text.strip() + \":\")\n",
    "        recipes_ingredients = \"\\n \".join(ing_list)\n",
    "    except:\n",
    "        logging.exception(f\"Exception when finding ingrediants of {page_link}\")\n",
    "    \n",
    "    if not recipes_ingredients:\n",
    "        logging.warning(f\"Cannot find recipe ingredients for {page_link}\")\n",
    "    return recipes_ingredients        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31efe23f-3103-4c05-94bc-bc7e51f223b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe(soup, page_link):\n",
    "    recipe = \"\"\n",
    "    try:\n",
    "        rec = soup.find('div', id=\"recipe_small_steps\").get_text(\"\\n\").strip()\n",
    "        recipe = \"\\n\".join(list(dict.fromkeys(rec.split(\"\\n\"))))\n",
    "    except:\n",
    "        logging.exception(f\"Exception when finding recipe for {page_link}\")\n",
    "\n",
    "    if not recipe:\n",
    "        logging.warning(f\"Cannot find recipe method for {page_link}\")\n",
    "    return recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e392c8-ec63-4fcb-9765-1b5ff9f69fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_and_serving(soup, page_link):\n",
    "    times = \"\"\n",
    "    servings = \"\"\n",
    "    other_info = \"\"\n",
    "    try:\n",
    "        prep_time = \"\"\n",
    "        cook_time = \"\"\n",
    "        total_tie = \"\"\n",
    "        \n",
    "        servings_tag = soup.find('span', attrs=dict(itemprop=\"recipeYield\"))\n",
    "        if servings_tag:\n",
    "            servings = str(servings_tag.text)\n",
    "        \n",
    "        prep_tag = soup.find('time', attrs=dict(itemprop=\"prepTime\"))\n",
    "        if prep_tag:\n",
    "            prep_time = prep_tag.text\n",
    "            times += \"Preparation Time: \" + prep_time+ \", \"\n",
    "\n",
    "        cook_tag = soup.find('time', attrs=dict(itemprop=\"cookTime\"))\n",
    "        if cook_tag:\n",
    "            cook_time = cook_tag.text\n",
    "            times += \"Cooking Time: \" + cook_time + \", \"\n",
    "        \n",
    "        total_time_tag = soup.find('time', itemprop='totalTime')\n",
    "        if total_time_tag:\n",
    "            span_tag = total_time_tag.find('span')\n",
    "            if span_tag:\n",
    "                span_tag.decompose()\n",
    "            total_time = total_time_tag.text\n",
    "            times += \"Total Time: \" + total_time + \", \"\n",
    "  \n",
    "        # Other time or coocking related info\n",
    "        tags_div = soup.find('div', id='recipe_tags')\n",
    "        if not tags_div:\n",
    "            tags_div = soup.find('div', id='ctl00_cntrightpanel_lblrecipeNameH2')\n",
    "            \n",
    "        p_tag = tags_div.find_next('p')\n",
    "        for t in p_tag.find_all('time'):\n",
    "            t.decompose()\n",
    "        if servings:\n",
    "            for serv_time in p_tag.find_all('span', attrs=dict(id=\"ctl00_cntrightpanel_lblServes\")):\n",
    "                serv_time.decompose()\n",
    "        \n",
    "        other_info = p_tag.get_text().replace(\"&nbsp\", \" \").split(\"Show me for\")[0].strip()        \n",
    "        if prep_time:\n",
    "              other_info = other_info.replace(\"Preparation Time:\", \"\")\n",
    "        if cook_time:\n",
    "              other_info = other_info.replace(\"Cooking Time:\", \"\")\n",
    "        if total_time:\n",
    "              other_info = other_info.replace(\"Total Time:\", \"\")\n",
    "        \n",
    "        times += other_info\n",
    "    \n",
    "    except:\n",
    "        logging.exception(f\"Error while finding time and serving for {page_link}\") \n",
    "\n",
    "    if not times or not servings:\n",
    "        logging.warning(f\"Cannot find times, or servings for {page_link}\")\n",
    "    return times, servings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818fee2c-b35c-4cb3-97e9-11cd88d03fc0",
   "metadata": {},
   "source": [
    "#### Get the pages and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae0f599e-ef99-42f7-8b7d-2a20e883ab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error when getting webpage from https://www.tarladalal.com/recipes-for-veg-recipes-gujarati-24?pageindex=1\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_7318/3896314710.py\", line 14, in get_webpage\n",
      "    links_page = urllib.request.urlopen(links_req, timeout=90).read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shalin/anaconda3/envs/genai/lib/python3.11/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shalin/anaconda3/envs/genai/lib/python3.11/urllib/request.py\", line 525, in open\n",
      "    response = meth(req, response)\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shalin/anaconda3/envs/genai/lib/python3.11/urllib/request.py\", line 634, in http_response\n",
      "    response = self.parent.error(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shalin/anaconda3/envs/genai/lib/python3.11/urllib/request.py\", line 563, in error\n",
      "    return self._call_chain(*args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shalin/anaconda3/envs/genai/lib/python3.11/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/shalin/anaconda3/envs/genai/lib/python3.11/urllib/request.py\", line 643, in http_error_default\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting recipies from page 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Retry Failed!!!\n"
     ]
    }
   ],
   "source": [
    "recipe_list_page_url = \"https://www.tarladalal.com/recipes-for-veg-recipes-gujarati-24?pageindex={0}\"\n",
    "recipe_url_prefix = \"https://www.tarladalal.com/\"\n",
    "for recipe_list_page_idx in range(1, 2):\n",
    "    recipe_list = []\n",
    "    print(f\"Getting recipies from page {recipe_list_page_idx}\")\n",
    "    list_url = recipe_list_page_url.format(recipe_list_page_idx)\n",
    "    recipe_list_page = get_webpage(list_url)\n",
    "    if not recipe_list_page:\n",
    "        continue\n",
    "    for recipe_span in recipe_list_page.find_all('span', attrs={\"class\":\"rcc_recipename\"}):\n",
    "        df_row = {}\n",
    "        df_row[\"recipe_list_url\"] = list_url\n",
    "        df_row[\"recipe_name\"] = recipe_span.text\n",
    "        recipe_url = recipe_url_prefix + recipe_span.find('a', href=True)['href']\n",
    "        df_row[\"recipe_url\"] = recipe_url    \n",
    "        # print(recipe_url)\n",
    "        recipe_page = get_webpage(recipe_url)\n",
    "        if not recipe_page:\n",
    "            logging.warn(f\"Couldn't find recipe page for {recipe_url}\")\n",
    "            continue\n",
    "        df_row[\"recipe_long_name\"] = recipe_page.find('span', id='ctl00_cntrightpanel_lblrecipeNameH2').text\n",
    "        df_row[\"recipe_ing\"] = get_ingrediants(recipe_page, recipe_url)\n",
    "        df_row[\"recipe\"] = get_recipe(recipe_page, recipe_url)\n",
    "        df_row[\"tags\"] = recipe_page.find('div', id='recipe_tags').get_text(\"\\n\").strip()\n",
    "        if not df_row[\"tags\"]:\n",
    "            logging.warn(f\"Couldn't find tags for {recipe_url}\")\n",
    "        times, servings = get_time_and_serving(recipe_page, recipe_url)\n",
    "        df_row[\"times\"] = times\n",
    "        df_row[\"servings\"] = servings\n",
    "        recipe_list.append(df_row)\n",
    "    recipe_df = pd.DataFrame(recipe_list)\n",
    "    recipe_df.to_csv(f\"../data/recipe_page_{recipe_list_page_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb791b6f-d929-4eec-a4f0-f5afb9a1419c",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "Page 1: Need other times in addition of cooking etc time.\n",
    "\n",
    "All Pages, \n",
    "- last line of recipe misses item name\n",
    "- Remove \"Tags\" from tags column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5565852-07d7-4029-bb5c-ce8ad3d08e41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Idx: 2\n",
      "Less ing for https://www.tarladalal.com/how-to-make-rajgira-flour-amaranth-flour-at-home-42738r\n",
      "Page Idx: 3\n",
      "Page Idx: 4\n",
      "Less ing for https://www.tarladalal.com/phulka-recipe-indian-chapati-recipe-4392r\n",
      "Less recipe for https://www.tarladalal.com/mango-milkshake-38492r\n",
      "Page Idx: 5\n",
      "Page Idx: 6\n",
      "Page Idx: 7\n",
      "Page Idx: 8\n",
      "Less ing for https://www.tarladalal.com/daria-chikki-roasted-chana-dal-chikki-40998r\n",
      "Less ing for https://www.tarladalal.com/alphonso-aamras-aaamras-recipe-40815r\n",
      "Page Idx: 9\n",
      "Page Idx: 10\n",
      "Page Idx: 11\n",
      "Page Idx: 12\n",
      "Page Idx: 13\n",
      "Less ing for https://www.tarladalal.com/peanut-chikki-41000r\n",
      "Less recipe for https://www.tarladalal.com/garlic-chutney--gujarati-recipe-573r\n",
      "Less recipe for https://www.tarladalal.com/onion-and-raw-mango-chunda--kaanda-aur-kairi-ka-choonda-40887r\n",
      "Less recipe for https://www.tarladalal.com/ukado-gujarati-lemon-grass-and-ginger-milk-41739r\n",
      "Page Idx: 14\n",
      "Page Idx: 15\n",
      "Less ing for https://www.tarladalal.com/coconut-chikki-kopra-chikki-made-in-jaggery-40999r\n",
      "Less recipe for https://www.tarladalal.com/multigrain-methi-thepla-dough-42288r\n",
      "Page Idx: 16\n",
      "Page Idx: 17\n",
      "Less recipe for https://www.tarladalal.com/green-garlic-spread-spread-for-rotis-41494r\n",
      "Page Idx: 18\n",
      "Less recipe for https://www.tarladalal.com/kacchi-keri-ni-chutney--gujarati-recipe-572r\n",
      "Page Idx: 19\n",
      "Page Idx: 20\n",
      "Less recipe for https://www.tarladalal.com/sambhaar-3440r\n",
      "Page Idx: 21\n",
      "Page Idx: 22\n",
      "Less ing for https://www.tarladalal.com/tamarind-water-imli-ka-pani-225r\n",
      "Page Idx: 23\n",
      "Less ing for https://www.tarladalal.com/kaachi-keri-no-sambhaar-577r\n",
      "Page Idx: 24\n",
      "Less recipe for https://www.tarladalal.com/zero-oil-purple-mogri-raita-42276r\n",
      "Less recipe for https://www.tarladalal.com/zero-oil-green-mogri-raita-42277r\n",
      "Page Idx: 25\n",
      "Less ing for https://www.tarladalal.com/how-to-sprout-vaal-lima-beans-42879r\n",
      "Less ing for https://www.tarladalal.com/low-fat-chaas-recipe--indian-low-fat-buttermilk-42744r\n",
      "Less ing for https://www.tarladalal.com/how-to-make-chaas--indian-buttermilk-recipe-42745r\n",
      "Less ing for https://www.tarladalal.com/how-to-cook-kodri-foxtail-millet-varagu-43035r\n",
      "Page Idx: 26\n",
      "Less recipe for https://www.tarladalal.com/masala-chaas-10318r\n",
      "Less recipe for https://www.tarladalal.com/mango-bhel-36449r\n",
      "Page Idx: 27\n",
      "Less ing for https://www.tarladalal.com/potato-sheera-15451r\n",
      "Less ing for https://www.tarladalal.com/sagoo-icecream-15469r\n",
      "Less recipe for https://www.tarladalal.com/sagoo-icecream-15469r\n",
      "Less recipe for https://www.tarladalal.com/rava-bhakri-15380r\n",
      "Page Idx: 28\n",
      "Page Idx: 29\n",
      "Less ing for https://www.tarladalal.com/phulka-14166r\n",
      "Page Idx: 30\n",
      "Less ing for https://www.tarladalal.com/puran-poli-12711r\n",
      "Less recipe for https://www.tarladalal.com/spicy-samosa-10497r\n",
      "Less recipe for https://www.tarladalal.com/handvoh-vegetable-bake-dish-12132r\n",
      "Page Idx: 31\n",
      "Page Idx: 32\n",
      "Page Idx: 33\n",
      "Page Idx: 34\n",
      "Less recipe for https://www.tarladalal.com/sabudana-khichhdi-8846r\n",
      "Less recipe for https://www.tarladalal.com/cutney-for-fast-9187r\n",
      "Less recipe for https://www.tarladalal.com/sabudana-shira-9513r\n",
      "Less recipe for https://www.tarladalal.com/onion-and-sev-raita-37199r\n",
      "Page Idx: 35\n",
      "Less recipe for https://www.tarladalal.com/doodhi-salad-37361r\n",
      "Less recipe for https://www.tarladalal.com/hariyali-chutney-37732r\n",
      "Page Idx: 36\n",
      "Page Idx: 37\n",
      "Less recipe for https://www.tarladalal.com/salad-with-papad-36132r\n",
      "Less recipe for https://www.tarladalal.com/srikhand-with-kesari-milk-masala-powder-36187r\n",
      "Less recipe for https://www.tarladalal.com/divine-mango-36232r\n",
      "Page Idx: 38\n"
     ]
    }
   ],
   "source": [
    "for page_id in range(2, 39):\n",
    "    df = pd.read_csv(f\"../data/recipe_page_{page_id}.csv\")\n",
    "    print(f\"Page Idx: {page_id}\")\n",
    "    for idx, row in df.iterrows():\n",
    "        if len(df.loc[idx, \"recipe_ing\"].split(\"\\n\")) <= 3:\n",
    "            print(f'Less ing for {row[\"recipe_url\"]}')\n",
    "    for idx, row in df.iterrows():\n",
    "        if len(df.loc[idx, \"recipe\"].split(\"\\n\")) <= 3:\n",
    "            print(f'Less recipe for {row[\"recipe_url\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "468e8171-30ea-449b-9e96-61d7b96f5d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "  vati \n",
      "chana dal (split Bengal gram)\n",
      "1/2\n",
      "  vati \n",
      "jaggery (gur)\n",
      "1/2\n",
      "  vati \n",
      "sugar\n",
      "10-12 veldodyanchi pud,\n",
      "thodese Keshar,\n",
      "1/4 jayfal pud,\n",
      "1 chamcha rava(aadhi thoda bhijat ghalava),\n",
      "1 vati kanik,\n",
      "1 chamcha tel,\n",
      "mith\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\" <br/><span itemprop=\"recipeIngredient\"><span>1</span>  vati <a href=\"glossary-chana-dal-split-bengal-gram-285i\"><span>chana dal (split Bengal gram)</span></a></span><br/><span itemprop=\"recipeIngredient\"><span>1/2</span>  vati <a href=\"glossary-jaggery-gur-gud-kala-gud-477i\"><span>jaggery (gur)</span></a></span><br/><span itemprop=\"recipeIngredient\"><span>1/2</span>  vati <a href=\"glossary-sugar-chini-shakkar-278i\"><span>sugar</span></a></span><br/>10-12 veldodyanchi pud,<br/>thodese Keshar,<br/>1/4 jayfal pud,<br/>1 chamcha rava(aadhi thoda bhijat ghalava),<br/>1 vati kanik,<br/>1 chamcha tel,<br/>mith<br/>\n",
    "\"\"\"\n",
    "sp = BeautifulSoup(s)\n",
    "print(sp.get_text(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7fc8bba-e0e6-4151-8463-54b37af7af76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Idx: 2\n",
      "Page Idx: 3\n",
      "Page Idx: 4\n",
      "Page Idx: 5\n",
      "Page Idx: 6\n",
      "Page Idx: 7\n",
      "Page Idx: 8\n",
      "Page Idx: 9\n",
      "Page Idx: 10\n",
      "Page Idx: 11\n",
      "Page Idx: 12\n",
      "Page Idx: 13\n",
      "Page Idx: 14\n",
      "Page Idx: 15\n",
      "Page Idx: 16\n",
      "Page Idx: 17\n",
      "Page Idx: 18\n",
      "Page Idx: 19\n",
      "Page Idx: 20\n",
      "Page Idx: 21\n",
      "Page Idx: 22\n",
      "Page Idx: 23\n",
      "Page Idx: 24\n",
      "Page Idx: 25\n",
      "Page Idx: 26\n",
      "Page Idx: 27\n",
      "Page Idx: 28\n",
      "Page Idx: 29\n",
      "Page Idx: 30\n",
      "Page Idx: 31\n",
      "Page Idx: 32\n",
      "Page Idx: 33\n",
      "Page Idx: 34\n",
      "Page Idx: 35\n",
      "Page Idx: 36\n",
      "Page Idx: 37\n",
      "Page Idx: 38\n"
     ]
    }
   ],
   "source": [
    "# Remove tags from tags column\n",
    "for page_id in range(2, 39):\n",
    "    df = pd.read_csv(f\"../data/recipe_page_{page_id}.csv\")\n",
    "    print(f\"Page Idx: {page_id}\")\n",
    "    # for idx, row in df.iterrows():\n",
    "    df['tags'] = df['tags'].str.replace(\"Tags\", \"\").str.strip()\n",
    "    df.to_csv(f\"../data/recipe_page_{page_id}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2bafe-10ee-4ca8-97b8-2a99a543f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
