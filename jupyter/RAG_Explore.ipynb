{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0a77b-cf25-487d-b0e5-aaa3677c9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90201ff5-66f1-40aa-9312-7ff8b637f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb615232-4beb-42d8-b250-30e1a09109ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_community.vectorstores.docarray.in_memory import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c84872-807f-4897-ba96-aa76b3962df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../data/recipe_page_1.csv\"\n",
    "loader = CSVLoader(file_path=file, csv_args={\"fieldnames\": [\"recipe_name\", \"ingredients\", \"recipe\", \"tags\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d1917-a86a-4fb5-93d6-28c5fa6302f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de146bc-7007-40e9-a395-2d67d0299414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab64adf-6524-46b7-8481-c62e7d1651ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embeddings\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb094620-c636-43ee-ba34-ad173959b0fe",
   "metadata": {},
   "source": [
    "### Ollama instruction\n",
    "- Install ollama: `curl -fsSL https://ollama.com/install.sh | sh`\n",
    "- Then run `ollama run <model name>` Model name from `https://ollama.com/library`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e40e99-6e16-4758-acdf-7707dcb3523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"stabilityai/stablelm-3b-4e1t\", #\"meta-llama/Meta-Llama-3-8B\",\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "#     timeout=600\n",
    "# )\n",
    "\n",
    "q = \"Provide all the recipe names, its recipe and all the ingrediants that uses besan. Do not provide or generate anything else.\"\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama3\")\n",
    "response = index.query(q, llm=llm)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a2a1f-733a-4b00-b340-3860eaca6f66",
   "metadata": {},
   "source": [
    "## Detailed Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f70b31-61a5-4b16-a4d3-b7de2667812f",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a77281-f9d5-4170-8220-913ef834f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_df = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 39):\n",
    "    file = f\"../data/recipe_page_{i}.csv\"\n",
    "    recipe_df = pd.read_csv(file, usecols=[\"recipe_name\", \"ingredients\", \"recipe\", \"tags\"])\n",
    "    csv_df=pd.concat([csv_df, recipe_df], ignore_index=True)\n",
    "print(csv_df.shape)\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa64d1-a479-4de4-a995-edbb4c60c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle rows\n",
    "csv_df = csv_df.sample(frac=1).reset_index(drop=True)\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c057333-1792-4716-bea5-1f7a4924fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/langchain-ai/langchain/issues/12601\n",
    "# Modified to create dictionary with column name and value\n",
    "from typing import Any, Iterator, List, Union\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "\n",
    "\n",
    "class BaseDataFrameLoader(BaseLoader):\n",
    "    def __init__(self, data_frame: Any, *, page_content_column: Union[str, List[str]] = \"text\"):\n",
    "        \"\"\"Initialize with dataframe object.\n",
    "\n",
    "        Args:\n",
    "            data_frame: DataFrame object.\n",
    "            page_content_column: Name of the column or list of column names containing the page content.\n",
    "              Defaults to \"text\".\n",
    "        \"\"\"\n",
    "        self.data_frame = data_frame\n",
    "        self.page_content_column = page_content_column\n",
    "\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        \"\"\"Lazy load records from dataframe.\"\"\"\n",
    "\n",
    "        for idx, row in self.data_frame.iterrows():\n",
    "            if isinstance(self.page_content_column, list):\n",
    "                text = ' '.join(f'{col}:{row[col]}' for col in self.page_content_column)\n",
    "            else:\n",
    "                text = f'{col}:{row[self.page_content_column]}'\n",
    "            metadata = row.to_dict()\n",
    "            if isinstance(self.page_content_column, list):\n",
    "                for col in self.page_content_column:\n",
    "                    metadata.pop(col, None)\n",
    "            else:\n",
    "                metadata.pop(self.page_content_column, None)\n",
    "            yield Document(page_content=text, metadata=metadata)\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load full dataframe.\"\"\"\n",
    "        return list(self.lazy_load())\n",
    "\n",
    "\n",
    "class DataFrameLoader(BaseDataFrameLoader):\n",
    "    \"\"\"Load `Pandas` DataFrame.\"\"\"\n",
    "\n",
    "    def __init__(self, data_frame: Any, page_content_column: Union[str, List[str]] = \"text\"):\n",
    "        \"\"\"Initialize with dataframe object.\n",
    "\n",
    "        Args:\n",
    "            data_frame: Pandas DataFrame object.\n",
    "            page_content_column: Name of the column or list of column names containing the page content.\n",
    "              Defaults to \"text\".\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import pandas as pd\n",
    "        except ImportError as e:\n",
    "            raise ImportError(\n",
    "                \"Unable to import pandas, please install with `pip install pandas`.\"\n",
    "            ) from e\n",
    "\n",
    "        if not isinstance(data_frame, pd.DataFrame):\n",
    "            raise ValueError(\n",
    "                f\"Expected data_frame to be a pd.DataFrame, got {type(data_frame)}\"\n",
    "            )\n",
    "        super().__init__(data_frame, page_content_column=page_content_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944b4df-8230-427b-aa8a-fad1075702d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders.dataframe import DataFrameLoader\n",
    "# loader = CSVLoader(file_path=file, csv_args={\"fieldnames\": [\"recipe_name\", \"ingredients\", \"recipe\"]})\n",
    "loader = DataFrameLoader(csv_df, page_content_column=[\"recipe_name\", \"ingredients\", \"recipe\", \"tags\"])\n",
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3a8f80-8d04-47a7-b8eb-8801ab704e2f",
   "metadata": {},
   "source": [
    " ### Emebeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615965a4-02d6-42e9-8e4d-027599c2a4ac",
   "metadata": {},
   "source": [
    "##### TODO:\n",
    "- Try out open ai ada model: https://platform.openai.com/docs/guides/embeddings/frequently-asked-questions \n",
    "- https://github.com/langchain-ai/langchain/issues/2442\n",
    "- Try  Faiss, pinecone, milvus Vdb\n",
    "- Check different document formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89427ab-03f0-4806-8074-c6d77474cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings()\n",
    "\n",
    "# individual_docs = []\n",
    "# for d in docs:\n",
    "#     individual_docs.append(d.page_content)\n",
    "\n",
    "# custom_embed = embedding_model.embed_documents(individual_docs)\n",
    "# len(custom_embed), len(custom_embed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf94985-b49c-4235-a336-6657b86fa917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "# os.environ[\"OPENAI_API_KEY\"] = '<KEY>'\n",
    "# embedding_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85582f4-891d-4a6b-bdc9-8d0fb29cfb45",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78a500-acf1-432f-8684-01e972d5cf11",
   "metadata": {},
   "source": [
    "<b> Doc retrival Improvements </b>\n",
    "\n",
    "- https://archive.ph/yn9Lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca0f57-a3ca-45fe-8687-45ac9af7993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "# db = DocArrayInMemorySearch.from_documents(\n",
    "#     docs, \n",
    "#     embedding_model\n",
    "# )\n",
    "# db = Chroma.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6340e80-2170-43b1-bd67-e7fb54747c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff2165e-18ea-4abf-b5fa-1df90dac04c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show me all recipes which uses Yellow moong\" #\"Show me all shaak recipe\" # \"Show me all dhokla recipe\" #\"Recipes which has besan as ingredients\"\n",
    "query = \"Show me all shaak recipes dish. Must avoid to look at word which are not shaak or shak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b565c9-94b5-4013-b5c2-e1f361a090f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_docs = db.similarity_search_with_relevance_scores(query, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1029e9f9-5d9f-4c79-ac93-24474c3e2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in searched_docs:\n",
    "    print(d)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e5e60-81a6-4dc7-a647-2cc269650804",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold': 0.45})\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff157f84-2393-4188-887a-aafda8a9333e",
   "metadata": {},
   "source": [
    "### Generation using LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8892567-f0f8-45e2-983a-ed7fa8a90ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"stabilityai/stablelm-3b-4e1t\", #\"meta-llama/Meta-Llama-3-8B\",\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "#     timeout=600\n",
    "# )\n",
    "\n",
    "# q = \"Provide all the recipe names, its recipe and all the ingrediants that uses besan. Do not provide or generate anything else.\"\n",
    "llm = Ollama(model=\"llama3\", temperature=0.5)\n",
    "# response = index.query(q, llm=llm)\n",
    "# display(Markdown(response))\n",
    "\n",
    "# from langchain_openai import OpenAI\n",
    "# llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c726a1-898c-4ad5-9f23-777f35ceeaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdocs = \"\".join([searched_docs[i][0].page_content for i in range(len(searched_docs))])\n",
    "final_query = f\"{qdocs} Question: {query} in a table in markdown and summarize each one\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c07dd-4f47-41ee-8d16-a34fd606f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(final_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72709ec-59b1-4dbf-b09c-240c78aea8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d696d6-51d1-4627-b01c-6df3938bccb5",
   "metadata": {},
   "source": [
    "### Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa8b6d-b290-4d34-9b01-4c66d626cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "import langchain\n",
    "\n",
    "langchain.debug =False\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold': 0.5})\n",
    "# For above steps, create LangChain chain\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\",\n",
    "    verbose=True,\n",
    "    retriever=retriever, \n",
    ")\n",
    "\n",
    "# Hellucinating with similar looking shak recipe. Like Shakarpara. But this is very wide query.\n",
    "# prompt = f\"Show me all shaak recipes dish. Must avoid to look at word which are not shaak or shak. Do not include Shakarpara\" \n",
    "\n",
    "# prompt = f\"Show me all recipes which uses Yellow moong\"\n",
    "\n",
    "# prompt = f\"I have dudhi/doodhi at home. Can you find me a recipe?\" # Hellucinating big time!\n",
    "# prompt = f\"I am craving for dosa. Can you show me recipes?\" # which are not farali or for upvas?\"\n",
    "prompt = f\"Can you share recipe for onion, potato and peas. Don't include shaak or sabji?\"\n",
    "response = qa_stuff.run(prompt + \" List all of the ingredients and the whole recipe to make from the document. Present in good format\")\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
